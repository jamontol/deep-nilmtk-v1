{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from deep_nilmtk.disaggregator import NILMExperiment\n",
    "from deep_nilmtk.models.pytorch import UNETNILM\n",
    "from deep_nilmtk.data.loader.pytorch import GeneralDataLoader\n",
    "from deep_nilmtk.utils.templates import ExperimentTemplate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hipe_with_baselines_agg-ALL'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_nilmtk.models.pytorch import UNETNILM, Seq2Point, Seq2Seq, SAED\n",
    "from deep_nilmtk.utils.templates.baseline_templates.hipe_template_agg import hipe_aggregated_15min_agg, hipe_aggregated_5min_agg, hipe_aggregated_5min_agg_noise\n",
    "\n",
    "\n",
    "#appliance = \"oven_2\"\n",
    "\n",
    "#model = 'Seq2Pointbaseline'\n",
    "# type = appliance.split('_')[0]\n",
    "# instance = int(appliance.split('_')[1])\n",
    "\n",
    "data_time_resolution = '5min_noise'\n",
    "\n",
    "use_optuna = False\n",
    "kfolds = 1\n",
    "if not use_optuna:\n",
    "    kfolds\n",
    "\n",
    "if data_time_resolution == '5min':\n",
    "\n",
    "    hipe_aggregated_5min_agg['experiment_settings']['use_optuna'] = use_optuna\n",
    "    hipe_aggregated_5min_agg['experiment_settings']['kfolds'] = kfolds\n",
    "    template_name = 'hipe_aggregated_5min_agg'\n",
    "    RESULTS_PATH = '../../results/hipe/hipe_with_baselines_agg_5min'\n",
    "\n",
    "elif data_time_resolution == '5min_noise':\n",
    "    hipe_aggregated_5min_agg_noise['experiment_settings']['use_optuna'] = use_optuna\n",
    "    hipe_aggregated_5min_agg_noise['experiment_settings']['kfolds'] = kfolds\n",
    "    template_name = 'hipe_aggregated_5min_agg_noise'\n",
    "    RESULTS_PATH = '../../results/hipe/hipe_with_baselines_agg_5min_noise'\n",
    "\n",
    "else: # '15min':\n",
    "\n",
    "    hipe_aggregated_15min_agg['experiment_settings']['use_optuna'] = use_optuna\n",
    "    hipe_aggregated_15min_agg['experiment_settings']['kfolds'] = kfolds\n",
    "    template_name = 'hipe_aggregated_15min_agg'\n",
    "    RESULTS_PATH = '../../results/hipe/hipe_with_baselines_agg_15min'\n",
    "\n",
    "list_appliances = [('motor',1),('motor',2), ('oven', 1), 'printer']\n",
    "list_models = [('Seq2Pointbaseline', 'pytorch'), ('Seq2Seqbaseline', 'pytorch'), ('DAE', 'pytorch'), ('SAED_model', 'pytorch'),('BERT4NILM', 'pytorch'), ('UNET', 'pytorch'),('UNET_quantile', 'pytorch')]\n",
    "\n",
    "# Cualquier parametro que querams modificar de get_template\n",
    "model_config ={\n",
    "    #'in_size': 121,\n",
    "    #'out_size': sequence_length, # 1 or n according number of appliances\n",
    "    'max_nb_epochs': 20,\n",
    "    'n_trials': 20,\n",
    "    'validation_metric': 'val_mae'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Appliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Testing for all algorithms\n",
      "Loading data for  hipe_agg  dataset\n",
      "Dropping missing values\n",
      "Generating predictions for : Seq2Pointbaseline\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed 2:   1%|          | 1/136 [00:00<00:04, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 136: 100%|██████████| 136/136 [00:01<00:00, 98.90it/s] \n",
      "............  mae  ..............\n",
      "         Seq2Pointbaseline\n",
      "motor 2           15.37466\n",
      "............  nde  ..............\n",
      "         Seq2Pointbaseline\n",
      "motor 2           0.219295\n",
      "............  rmse  ..............\n",
      "         Seq2Pointbaseline\n",
      "motor 2          59.931553\n",
      "............  relative_error  ..............\n",
      "         Seq2Pointbaseline\n",
      "motor 2           0.094663\n",
      "............  f1score  ..............\n",
      "         Seq2Pointbaseline\n",
      "motor 2           0.785981\n",
      "Experiment took: 1.0 minutes\n"
     ]
    }
   ],
   "source": [
    "appliance = ('motor',2)\n",
    "list_models = [('Seq2Pointbaseline', 'pytorch')] #('Seq2Pointbaseline', 'pytorch')]\n",
    "model = list_models[0][0]\n",
    "\n",
    "EXPERIMENT_NAME = f\"hipe_with_baselines_agg-{appliance}-{model}\"\n",
    "\n",
    "template = ExperimentTemplate( data_path=DATA_PATH,\n",
    "                template_name=template_name,\n",
    "                list_appliances=[appliance], #(type,instance)],\n",
    "                list_baselines_backends= list_models,\n",
    "                model_config = model_config\n",
    "                #  in_size=None,\n",
    "                #  out_size=None,\n",
    "                # max_nb_epochs=None\n",
    "                )\n",
    "template.run_template(EXPERIMENT_NAME,\n",
    "                    RESULTS_PATH,\n",
    "                    f'{RESULTS_PATH}/mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hipe_with_baselines_agg-('motor', 2)-Seq2Pointbaseline\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['error_keys', 'errors', 'train_mains', 'train_submeters', 'test_mains', 'test_submeters', 'gt', 'predictions', 'execution_time'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"../../results/hipe/hipe_with_baselines_agg_{data_time_resolution}/{EXPERIMENT_NAME}.p\", 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq2Pointbaseline</th>\n",
       "      <th>True consumption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:00:00+01:00</th>\n",
       "      <td>7.861515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:05:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:10:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:15:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:20:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Seq2Pointbaseline  True consumption\n",
       "                                                              \n",
       "2017-12-01 00:00:00+01:00           7.861515               0.0\n",
       "2017-12-01 00:05:00+01:00           0.000000               0.0\n",
       "2017-12-01 00:10:00+01:00           0.000000               0.0\n",
       "2017-12-01 00:15:00+01:00           0.000000               0.0\n",
       "2017-12-01 00:20:00+01:00           0.000000               0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_results=pd.DataFrame({\n",
    "    key: results['predictions'][key].values.reshape(-1) for key in results['predictions']\n",
    "}, index= results['test_submeters'][0][1][0].index)\n",
    "wm_results['True consumption'] = results['test_submeters'][0][1][0].values\n",
    "\n",
    "wm_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if use_optuna:\n",
    "    training_type=\"-HPO\"\n",
    "else: \n",
    "    training_type=\"\"\n",
    "\n",
    "fig = px.scatter(wm_results).update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(title_text=f\"{appliance}{training_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Appliance-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Testing for all algorithms\n",
      "Loading data for  hipe_agg  dataset\n",
      "Dropping missing values\n",
      "Generating predictions for : Seq2Pointbaseline\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed 1:   0%|          | 0/136 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 136: 100%|██████████| 136/136 [00:01<00:00, 91.32it/s]\n",
      "processed 136: 100%|██████████| 136/136 [00:01<00:00, 84.66it/s]\n",
      "processed 136: 100%|██████████| 136/136 [00:01<00:00, 82.19it/s]\n",
      "processed 136: 100%|██████████| 136/136 [00:01<00:00, 90.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for : Seq2Seqbaseline\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 132.16it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 129.50it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 134.71it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:00<00:00, 137.92it/s]\n",
      "(8542, 99, 1)\n",
      "(8542, 99, 1)\n",
      "(8542, 99, 1)\n",
      "(8542, 99, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for : DAE\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed: 136: 100%|██████████| 136/136 [00:00<00:00, 172.82it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:00<00:00, 172.31it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:00<00:00, 161.66it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:00<00:00, 175.39it/s]\n",
      "(8542, 1, 99)\n",
      "(8542, 1, 99)\n",
      "(8542, 1, 99)\n",
      "(8542, 1, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for : SAED_model\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed 136: 100%|██████████| 136/136 [00:02<00:00, 54.34it/s]\n",
      "processed 136: 100%|██████████| 136/136 [00:02<00:00, 48.38it/s]\n",
      "processed 136: 100%|██████████| 136/136 [00:02<00:00, 48.44it/s]\n",
      "processed 136: 100%|██████████| 136/136 [00:02<00:00, 46.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for : BERT4NILM\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'backend': 'pytorch', 'use_optuna': False, 'n_trials': 20, 'log_artificat': False, 'logs_path': 'logs', 'checkpoints_path': 'checkpoints', 'version': 0, 'max_nb_epochs': 20, 'batch_size': 64, 'clip_value': 10, 'learning_rate': 0.0001, 'patience_optim': 5, 'patience_check': 5, 'optimizer': 'adam', 'weight_decay': 0.0, 'momentum': None, 'decay_step': 100, 'gamma': 0.1, 'stride': 1, 'out_size': 1, 'in_size': 99, 'border': 0, 'multi_appliance': False, 'custom_preprocess': 'bert_preprocess', 'custom_postprocess': 'bert_postprocess', 'input_norm': 'z-norm', 'target_norm': 'z-norm', 'model_name': 'BERT4NILM', 'model_class': None, 'loader_class': <class 'deep_nilmtk.data.loader.pytorch.bert_dataloader.BERTDataset'>, 'seq_type': 'seq2point', 'point_position': 'mid_position', 'quantiles': [0.1, 0.25, 0.5, 0.75, 0.9], 'threshold_method': 'at', 'kfolds': 1, 'gap': 0, 'test_size': None, 'feature_type': 'mains', 'experiment_label': '', 'main_mu': 150.0, 'main_std': 350.0, 'seed': 3407, 'q_filter': None, 'train': 1, 'z_dim': 10, 'hidden_dim': 128, 'mdn_dist_type': 'normal', 'data': 'hipe_5min_agg_noise.h5', 'figure_path': 'figures', 'num_workers': 0, 'f': '/home/jrml/.local/share/jupyter/runtime/kernel-v34378c82a0c835f51f7bc84706feb8037efefbfd3.json', 'latent_size': 1024, 'validation_metric': 'val_mae', 'threshold': 50, 'cutoff': 650, 'min_on': 1800, 'min_off': 900, 'c0': 1, 'aggregate_cutoff': 9000, 'template_name': 'hipe_aggregated_5min_agg_noise', 'results_path': '../../results/hipe/hipe_with_baselines_agg_5min_noise', 'exp_name': 'hipe_with_baselines_agg-ALL', 'mean': array([[319.83341414]]), 'std': array([[880.42200364]])}\n",
      "processed: 134: 100%|██████████| 134/134 [00:17<00:00,  7.59it/s]\n",
      "processed: 134: 100%|██████████| 134/134 [00:15<00:00,  8.93it/s]\n",
      "processed: 134: 100%|██████████| 134/134 [00:16<00:00,  8.16it/s]\n",
      "processed: 134: 100%|██████████| 134/134 [00:14<00:00,  9.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for : UNET\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 98.68it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 99.79it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 101.75it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 99.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data is preprocessed using default pre-preprocessing function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for : UNET_quantile\n",
      "(8640, 1)\n",
      "doing input normalisation on test data using main_params:\n",
      "{'mean': array([[319.83711822]]), 'std': array([[880.45865654]])}\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 89.13it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 88.30it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 101.90it/s]\n",
      "processed: 136: 100%|██████████| 136/136 [00:01<00:00, 91.95it/s]\n",
      "............  mae  ..............\n",
      "            Seq2Pointbaseline  Seq2Seqbaseline         DAE  SAED_model  \\\n",
      "(motor, 1)           9.890777        43.698040   19.647373   17.809008   \n",
      "(motor, 2)          13.246608       224.646851  110.429893   27.494171   \n",
      "(oven, 1)           59.616482       282.480621  202.422836   74.392921   \n",
      "printer             16.262524        55.836823   38.910553   20.264656   \n",
      "\n",
      "             BERT4NILM        UNET  UNET_quantile  \n",
      "(motor, 1)   14.457746   23.859463      13.188826  \n",
      "(motor, 2)  134.939041  117.772903      22.118183  \n",
      "(oven, 1)   137.900146  241.527588     134.965240  \n",
      "printer      29.144573   30.232635      14.186001  \n",
      "............  nde  ..............\n",
      "            Seq2Pointbaseline  Seq2Seqbaseline       DAE  SAED_model  \\\n",
      "(motor, 1)           0.603597         1.021858  0.989882    0.961905   \n",
      "(motor, 2)           0.203178         1.136081  0.849098    0.388590   \n",
      "(oven, 1)            0.412344         1.122936  0.912907    0.486103   \n",
      "printer              0.624531         0.975303  0.908604    0.685917   \n",
      "\n",
      "            BERT4NILM      UNET  UNET_quantile  \n",
      "(motor, 1)   1.005413  1.141017       0.959547  \n",
      "(motor, 2)   1.165655  1.079533       0.421773  \n",
      "(oven, 1)    1.000000  1.306282       0.985766  \n",
      "printer      1.052077  0.939975       0.695966  \n",
      "............  rmse  ..............\n",
      "            Seq2Pointbaseline  Seq2Seqbaseline         DAE  SAED_model  \\\n",
      "(motor, 1)          47.161919        79.842674   77.344208   75.158249   \n",
      "(motor, 2)          55.526806       310.481354  232.051392  106.198288   \n",
      "(oven, 1)          294.799713       802.828064  652.670349  347.532684   \n",
      "printer             56.173141        87.723083   81.723907   61.694435   \n",
      "\n",
      "             BERT4NILM        UNET  UNET_quantile  \n",
      "(motor, 1)   78.557701   89.153114      74.974007  \n",
      "(motor, 2)  318.563782  295.027466     115.267075  \n",
      "(oven, 1)   714.936401  933.908875     704.760071  \n",
      "printer      94.628540   84.545525      62.598309  \n",
      "............  relative_error  ..............\n",
      "            Seq2Pointbaseline  Seq2Seqbaseline       DAE  SAED_model  \\\n",
      "(motor, 1)           1.358025         1.230412  3.412575    5.166594   \n",
      "(motor, 2)           0.134520         1.172771  0.677963    0.866674   \n",
      "(oven, 1)            8.324506         1.763727  0.583021    4.676522   \n",
      "printer              1.854394         1.229618  0.989335    1.673957   \n",
      "\n",
      "             BERT4NILM       UNET  UNET_quantile  \n",
      "(motor, 1)   13.632387   5.835225       5.689632  \n",
      "(motor, 2)   76.696030  17.238716       4.149498  \n",
      "(oven, 1)   137.900146  93.867676       5.975661  \n",
      "printer      23.977535   2.957224       3.322372  \n",
      "............  f1score  ..............\n",
      "            Seq2Pointbaseline  Seq2Seqbaseline       DAE  SAED_model  \\\n",
      "(motor, 1)           0.540845         0.070567  0.161595    0.252888   \n",
      "(motor, 2)           0.724763         0.177407  0.385073    0.640888   \n",
      "(oven, 1)            0.542629         0.266453  0.683369    0.572581   \n",
      "printer              0.662690         0.140136  0.338094    0.603568   \n",
      "\n",
      "            BERT4NILM      UNET  UNET_quantile  \n",
      "(motor, 1)   0.000000  0.237113       0.254545  \n",
      "(motor, 2)   0.093541  0.478079       0.845721  \n",
      "(oven, 1)    0.000000  0.378378       0.794352  \n",
      "printer      0.034079  0.502476       0.734793  \n",
      "Experiment took: 47.9 minutes\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = f\"hipe_with_baselines_agg-ALL\"\n",
    "\n",
    "template = ExperimentTemplate( data_path=DATA_PATH,\n",
    "                template_name=template_name,\n",
    "                list_appliances=list_appliances, #[appliance], #(type,instance)],\n",
    "                list_baselines_backends= list_models,\n",
    "                model_config = model_config\n",
    "                #  in_size=None,\n",
    "                #  out_size=None,\n",
    "                # max_nb_epochs=None\n",
    "                )\n",
    "template.run_template(EXPERIMENT_NAME,\n",
    "                    RESULTS_PATH,\n",
    "                    f'{RESULTS_PATH}/mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5min_noise'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_time_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['error_keys', 'errors', 'train_mains', 'train_submeters', 'test_mains', 'test_submeters', 'gt', 'predictions', 'execution_time'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"../../results/hipe/hipe_with_baselines_agg_{data_time_resolution}/hipe_with_baselines_agg-ALL.p\", 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_type = results['predictions']['Seq2Pointbaseline'].columns.get_level_values(0)[0]\n",
    "device_instances = list(results['predictions']['Seq2Pointbaseline'].columns)\n",
    "\n",
    "wm_results = []\n",
    "\n",
    "for ind, instance in enumerate(device_instances): \n",
    "\n",
    "    wm_results.append(pd.DataFrame({\n",
    "        #key: results['predictions'][key][device_type].values.reshape(-1) for key in results['predictions']\n",
    "        key: results['predictions'][key][instance].values.reshape(-1) for key in results['predictions']\n",
    "    }, index= results['test_submeters'][ind][1][0].index))\n",
    "    wm_results[ind]['True consumption']= results['test_submeters'][ind][1][0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if use_optuna:\n",
    "    training_type=\"-HPO\"\n",
    "else: \n",
    "    training_type=\"\"\n",
    "\n",
    "fig = px.scatter(wm_results[0]).update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(title_text=f\"{training_type}-Chip Saw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if hipe_aggregated_15min_agg['experiment_settings']['use_optuna']:\n",
    "    training_type=\"-HPO\"\n",
    "else: \n",
    "    training_type=\"\"\n",
    "\n",
    "fig = px.scatter(wm_results[1]).update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(title_text=f\"{training_type}-Vacuum Pump 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if hipe_aggregated_15min_agg['experiment_settings']['use_optuna']:\n",
    "    training_type=\"-HPO\"\n",
    "else: \n",
    "    training_type=\"\"\n",
    "\n",
    "fig = px.scatter(wm_results[2]).update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(title_text=f\"{training_type}-High Temperature Oven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if hipe_aggregated_15min_agg['experiment_settings']['use_optuna']:\n",
    "    training_type=\"-HPO\"\n",
    "else: \n",
    "    training_type=\"\"\n",
    "\n",
    "fig = px.scatter(wm_results[3]).update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(title_text=f\"{training_type}-Printer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if hipe_aggregated_15min_agg['experiment_settings']['use_optuna']:\n",
    "    training_type=\"-HPO\"\n",
    "else: \n",
    "    training_type=\"\"\n",
    "\n",
    "fig = px.scatter(wm_results[3]).update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(title_text=f\"{training_type}-Printer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for all appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:the in_size and max_nb_epochs must be added to the list of this parameters\n",
      "WARNING:root:the in_size and max_nb_epochs must be added to the list of this parameters\n"
     ]
    }
   ],
   "source": [
    "from deep_nilmtk.models.pytorch import UNETNILM, Seq2Point, Seq2Seq, SAED\n",
    "from deep_nilmtk.utils.templates.baseline_templates.hipe_template import hipe_aggregated_15min\n",
    "\n",
    "hipe_aggregated_15min['experiment_settings']['use_optuna'] = True\n",
    "\n",
    "models = ['Seq2Pointbaseline', 'SAED_model', 'Seq2Seqbaseline', 'BERT4NILM', 'DAE', 'UNET', 'UNET_quantile']\n",
    "\n",
    "# Cualquier parametro que querams modificar de get_template\n",
    "model_config ={\n",
    "    'in_size': 121,\n",
    "    #'out_size': sequence_length, # 1 or n according number of appliances\n",
    "    'max_nb_epochs': 10,\n",
    "    'n_trials': 10\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    EXPERIMENT_NAME = model\n",
    "    \n",
    "    template = ExperimentTemplate(data_path=DATA_PATH,\n",
    "                    template_name='hipe_aggregated_15min',\n",
    "                    list_appliances=[('motor',2), ('motor',4), ('motor',5), ('oven', 1), ('oven', 2), ('oven', 3),'printer','washing machine'],\n",
    "                    list_baselines_backends=[(model, 'pytorch')], # ('DAE', 'pytorch')],#('Seq2Pointbaseline', 'pytorch'),('Seq2Pointbaseline', 'pytorch')], , ('UNET', 'pytorch'), ('UNET_quantile', 'pytorch')] ,#('Seq2Pointbaseline', 'pytorch')],#, ('SAED_model', 'pytorch'), ('unet_base', 'pytorch')], #], #models.py with get_template patrms , \n",
    "                    model_config = model_config\n",
    "                    #  in_size=None,\n",
    "                    #  out_size=None,\n",
    "                    # max_nb_epochs=None\n",
    "                    )\n",
    "    \n",
    "    template.run_template(EXPERIMENT_NAME,\n",
    "                     RESULTS_PATH,\n",
    "                     f'{RESULTS_PATH}/mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['error_keys', 'errors', 'train_mains', 'train_submeters', 'test_mains', 'test_submeters', 'gt', 'predictions', 'execution_time'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{RESULTS_PATH}/{EXPERIMENT_NAME}.p', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq2Pointbaseline</th>\n",
       "      <th>True consumption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:00:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:15:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:30:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:45:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 01:00:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30 22:45:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30 23:00:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30 23:15:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30 23:30:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30 23:45:00+01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Seq2Pointbaseline  True consumption\n",
       "                                                              \n",
       "2017-12-01 00:00:00+01:00                0.0               0.0\n",
       "2017-12-01 00:15:00+01:00                0.0               0.0\n",
       "2017-12-01 00:30:00+01:00                0.0               0.0\n",
       "2017-12-01 00:45:00+01:00                0.0               0.0\n",
       "2017-12-01 01:00:00+01:00                0.0               0.0\n",
       "...                                      ...               ...\n",
       "2017-12-30 22:45:00+01:00                0.0               0.0\n",
       "2017-12-30 23:00:00+01:00                0.0               0.0\n",
       "2017-12-30 23:15:00+01:00                0.0               0.0\n",
       "2017-12-30 23:30:00+01:00                0.0               0.0\n",
       "2017-12-30 23:45:00+01:00                0.0               0.0\n",
       "\n",
       "[2880 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_results=pd.DataFrame({\n",
    "    key: results['predictions'][key].values.reshape(-1) for key in results['predictions']\n",
    "}, index= results['test_submeters'][0][1][0].index)\n",
    "wm_results['True consumption']= results['test_submeters'][0][1][0].values\n",
    "\n",
    "wm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nseq2seq_base = NILMExperiment({\\n                \"model_class\": Seq2Seq,\\n                \"loader_class\": GeneralDataLoader,\\n                \\'model_name\\':\\'seq2seq_base\\',\\n                #\\'in_size\\': sequence_length,\\n                \\'custom_preprocess\\': None,\\n                #\\'out_size\\': 128 # 1*params[\\'n_zize\\'] or n*in_size according number of appliances \\n                #\\'feature_type\\': \\'mains\\', # get_template()\\n                #\\'input_norm\\': \\'z-norm\\', # get_template()\\n                #\\'target_norm\\': \\'z-norm\\', # get_template()\\n                #\\'seq_type\\': \\'seq2seq\\', # get_template()\\n                #\\'learning_rate\\': 10e-5,  # get_template()\\n                #\\'max_nb_epochs\\': max_epochs,\\n                \\'optuna\\':optuna\\n            })\\n\\nunet_base = NILMExperiment({\\n    \\n    \"model_class\": UNETNILM,        \\n    \"loader_class\": GeneralDataLoader,\\n    \"model_name\": \\'unet_base\\',\\n    #\\'in_size\\': sequence_length,\\n    \\'custom_preprocess\\': None,\\n    #\\'out_size\\': 1, # 1 or n according number of appliances \\n    #\\'feature_type\\': \\'mains\\', # get_template()\\n    #\\'input_norm\\': \\'z-norm\\', # get_template()\\n    #\\'target_norm\\': \\'z-norm\\', # get_template()\\n    #\\'seq_type\\': \\'seq2seq\\', # get_template()\\n    #\\'learning_rate\\': 10e-5,  # get_template()\\n    #\\'max_nb_epochs\\': max_epochs,\\n    \\'optuna\\':optuna\\n\\n})\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# sequence_length = 121\n",
    "# max_epochs = 10\n",
    "optuna = False\n",
    "\n",
    "seq2point_hpo = NILMExperiment({\n",
    "                \"model_class\": Seq2Point,\n",
    "                \"loader_class\": GeneralDataLoader,\n",
    "                'model_name':'seq2point_base',\n",
    "                'in_size': sequence_length,\n",
    "                'custom_preprocess': None,\n",
    "                #'out_size': 1, # 1 or n according number of appliances \n",
    "                'feature_type': 'mains', \n",
    "                'input_norm': 'z-norm', # get_template()\n",
    "                'target_norm': 'z-norm', # get_template()\n",
    "                #'seq_type': 'seq2point', # get_template()\n",
    "                'point_position':'mid_position', # get_template()\n",
    "                'learning_rate': 10e-5,  # get_template()\n",
    "                'max_nb_epochs': max_epochs,\n",
    "                'optuna': optuna,\n",
    "                'n_trials': 50\n",
    "            })\n",
    "\n",
    "SAED_hpo = NILMExperiment({\n",
    "\n",
    "    \"model_class\": SAED,        \n",
    "    \"loader_class\": GeneralDataLoader,\n",
    "    \"model_name\": 'saed_base',\n",
    "    #'in_size': sequence_length,\n",
    "    'custom_preprocess': None,\n",
    "    'out_size': 1, # 1 or n according number of appliances \n",
    "    'feature_type': 'mains', # get_template() \n",
    "    'input_norm': 'z-norm', # get_template()\n",
    "    'target_norm': 'z-norm', # get_template()\n",
    "    #'seq_type': 'seq2point', # get_template()\n",
    "    'point_position':'mid_position', # get_template()\n",
    "    'attention_type': 'dot',\n",
    "    'learning_rate': 10e-5,  # get_template()¡\n",
    "    'max_nb_epochs': max_epochs,\n",
    "    'optuna':optuna,\n",
    "    'n_trials': 50\n",
    "\n",
    "}) \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "seq2seq_base = NILMExperiment({\n",
    "                \"model_class\": Seq2Seq,\n",
    "                \"loader_class\": GeneralDataLoader,\n",
    "                'model_name':'seq2seq_base',\n",
    "                #'in_size': sequence_length,\n",
    "                'custom_preprocess': None,\n",
    "                #'out_size': 128 # 1*params['n_zize'] or n*in_size according number of appliances \n",
    "                #'feature_type': 'mains', # get_template()\n",
    "                #'input_norm': 'z-norm', # get_template()\n",
    "                #'target_norm': 'z-norm', # get_template()\n",
    "                #'seq_type': 'seq2seq', # get_template()\n",
    "                #'learning_rate': 10e-5,  # get_template()\n",
    "                #'max_nb_epochs': max_epochs,\n",
    "                'optuna':optuna\n",
    "            })\n",
    "\n",
    "unet_base = NILMExperiment({\n",
    "    \n",
    "    \"model_class\": UNETNILM,        \n",
    "    \"loader_class\": GeneralDataLoader,\n",
    "    \"model_name\": 'unet_base',\n",
    "    #'in_size': sequence_length,\n",
    "    'custom_preprocess': None,\n",
    "    #'out_size': 1, # 1 or n according number of appliances \n",
    "    #'feature_type': 'mains', # get_template()\n",
    "    #'input_norm': 'z-norm', # get_template()\n",
    "    #'target_norm': 'z-norm', # get_template()\n",
    "    #'seq_type': 'seq2seq', # get_template()\n",
    "    #'learning_rate': 10e-5,  # get_template()\n",
    "    #'max_nb_epochs': max_epochs,\n",
    "    'optuna':optuna\n",
    "\n",
    "})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.extend_experiment({'seq2point_hpo': seq2point_hpo, 'SAED_hpo': SAED_hpo}) #, 'SAED_base': SAED_base, 'seq2seq_base': seq2seq_base, 'unet_base': unet_base,})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NILM-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
